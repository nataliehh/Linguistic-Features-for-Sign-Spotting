{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b430a4",
   "metadata": {},
   "source": [
    "# Sign selection - DO NOT UPLOAD TO FINAL REPO\n",
    "\n",
    "This notebook finds out which videos a specific sign is present in. This is useful for when we want to check the sign spotting for a specific video and we need a target sign as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ca49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pympi\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Keep python tools up to date\n",
    "from tools import tools, constants\n",
    "importlib.reload(tools)\n",
    "importlib.reload(constants)\n",
    "\n",
    "# Import all functions from the tools\n",
    "from tools.tools import*\n",
    "from tools.constants import PATHS # Path constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6ca7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations...\n"
     ]
    }
   ],
   "source": [
    "# Root where all the annotated .eaf sign files are present\n",
    "dataset_root = PATHS['cngt_vids_and_eaf']\n",
    "\n",
    "dataset_anns_path = PATHS['dataset_anns']\n",
    "\n",
    "# List the .eaf files in the root directory to investigate\n",
    "anns_in_dir = [file for file in os.listdir(dataset_root) if file.endswith('.eaf')]\n",
    "\n",
    "if os.path.exists(dataset_anns_path):\n",
    "    print('Loading annotations...')\n",
    "    anns_with_tiers = load_dict(dataset_anns_path)\n",
    "else:\n",
    "    print('Making annotations without manual simultaneity...')\n",
    "    anns_with_tiers = {}\n",
    "    for i, ann_file in enumerate(anns_in_dir):\n",
    "        print(i, end = '\\r')\n",
    "        # Read in the Eaf file \n",
    "        eaf_file = pympi.Elan.Eaf(os.path.join(dataset_root, ann_file))\n",
    "\n",
    "        # Get the glosses and mouthings of the file\n",
    "        anns_dict, _ = get_gloss_vals(eaf_file, True)\n",
    "        anns_dict = man_sim_and_hand_dist(anns_dict, manual_sim = False)\n",
    "\n",
    "        # Store the glosses, mouthings and tiers\n",
    "        anns_with_tiers[ann_file] = anns_dict\n",
    "    print('Storing...')\n",
    "    with open(dataset_anns_path, 'wb') as f:\n",
    "        pickle.dump(anns_with_tiers, f)\n",
    "        \n",
    "# Signbank dictionary info\n",
    "df = pd.read_csv(PATHS['signbank_dictionary_info'])\n",
    "\n",
    "id_split = load_dict(PATHS['CNGT_split_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83943e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing which signers and videos belong in the train and test set\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "for key in id_split:\n",
    "    # Change format from CNGTyyyy_Sxxx -> Sxxx_CNGTyyyy.eaf\n",
    "    # So it matches the annotation file names (.eaf files)\n",
    "    reorder = sorted(set(['_'.join(x.split('_')[::-1]) + '.eaf' for x in id_split[key]]))\n",
    "    if key == 'Train':\n",
    "        train_ids = reorder\n",
    "    else:\n",
    "        test_ids = reorder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e78ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S011_CNGT0215.eaf NU-A [(75800, 76840, 'GlossR S1'), (83480, 84480, 'GlossR S1')]\n",
      "S011_CNGT0217.eaf NU-A [(5480, 6040, 'GlossR S1'), (21920, 22400, 'GlossR S1')]\n",
      "S011_CNGT0223.eaf NU-A [(138260, 138590, 'GlossR S1'), (145930, 146110, 'GlossR S1'), (251600, 251680, 'GlossR S1'), (252360, 252640, 'GlossR S1')]\n",
      "S012_CNGT0208.eaf NU-A [(88200, 88360, 'GlossR S2')]\n",
      "S012_CNGT0211.eaf NU-A [(36400, 36520, 'GlossR S2')]\n",
      "S012_CNGT0215.eaf NU-A [(65760, 65920, 'GlossR S2'), (69560, 69840, 'GlossR S2'), (114120, 114200, 'GlossR S2'), (114560, 114640, 'GlossR S2'), (352720, 352880, 'GlossR S2')]\n",
      "S012_CNGT0217.eaf NU-A [(21080, 21200, 'GlossR S2'), (70040, 70440, 'GlossR S2'), (71160, 71480, 'GlossR S2'), (74640, 74840, 'GlossR S2'), (76400, 76480, 'GlossR S2'), (76800, 76880, 'GlossR S2')]\n",
      "S019_CNGT0386.eaf NU-A [(124160, 124280, 'GlossL S2'), (105160, 105280, 'GlossR S2')]\n",
      "S019_CNGT0390.eaf NU-A [(106360, 106480, 'GlossR S2')]\n",
      "S020_CNGT0370.eaf NU-A [(46520, 46840, 'GlossR S1')]\n",
      "S020_CNGT0387.eaf NU-A [(70800, 70840, 'GlossR S1')]\n",
      "S020_CNGT0388.eaf NU-A [(85360, 85560, 'GlossR S1'), (191200, 191360, 'GlossR S1')]\n",
      "S027_CNGT0541.eaf NU-A [(97280, 97320, 'GlossR S1')]\n",
      "S027_CNGT0566.eaf NU-A [(39760, 40040, 'GlossR S1')]\n",
      "S039_CNGT0859.eaf NU-A [(57400, 57600, 'GlossR S2')]\n",
      "S039_CNGT0862.eaf NU-A [(225560, 225720, 'GlossR S2')]\n",
      "S040_CNGT0832.eaf NU-A [(417560, 417880, 'GlossR S1'), (418040, 418280, 'GlossR S1'), (418680, 419200, 'GlossR S1')]\n",
      "S040_CNGT0859.eaf NU-A [(36720, 36880, 'GlossR S1')]\n",
      "S040_CNGT0861.eaf NU-A [(130760, 131440, 'GlossR S1'), (180480, 180560, 'GlossR S1'), (182760, 182800, 'GlossR S1')]\n",
      "S040_CNGT0862.eaf NU-A [(84360, 84560, 'GlossL S1'), (208200, 208400, 'GlossR S1')]\n",
      "S042_CNGT0904.eaf NU-A [(52880, 53120, 'GlossR S1')]\n",
      "S045_CNGT1004.eaf NU-A [(83640, 83760, 'GlossR S1'), (105240, 106480, 'GlossR S1'), (107240, 107400, 'GlossR S1')]\n",
      "S045_CNGT1006.eaf NU-A [(52400, 52600, 'GlossR S1')]\n",
      "S045_CNGT1028.eaf NU-A [(32800, 33040, 'GlossR S1'), (168520, 168760, 'GlossR S1'), (169480, 169560, 'GlossR S1'), (186000, 186480, 'GlossR S1')]\n",
      "S045_CNGT1046.eaf NU-A [(3440, 3600, 'GlossR S1')]\n",
      "S046_CNGT1004.eaf NU-A [(5040, 5160, 'GlossR S2'), (21040, 21240, 'GlossR S2'), (23920, 24240, 'GlossR S2'), (38080, 38240, 'GlossR S2'), (39080, 39320, 'GlossR S2')]\n",
      "S046_CNGT1028.eaf NU-A [(189120, 189280, 'GlossR S2')]\n",
      "S051_CNGT1183.eaf NU-A [(230200, 230520, 'GlossL S1')]\n",
      "S051_CNGT1185.eaf NU-A [(115720, 116080, 'GlossL S1'), (172240, 172920, 'GlossL S1'), (201480, 201720, 'GlossL S1')]\n",
      "S052_CNGT1157.eaf NU-A [(22480, 22640, 'GlossR S2'), (90000, 90160, 'GlossR S2')]\n",
      "S052_CNGT1183.eaf NU-A [(209000, 209480, 'GlossR S2')]\n",
      "S052_CNGT1185.eaf NU-A [(249040, 249880, 'GlossR S2'), (294280, 297040, 'GlossR S2')]\n",
      "S054_CNGT1206.eaf NU-A [(49440, 49880, 'GlossR S2')]\n",
      "S055_CNGT1261.eaf NU-A [(280880, 280960, 'GlossR S1'), (283240, 283400, 'GlossR S1'), (285120, 285720, 'GlossR S1')]\n",
      "S056_CNGT1261.eaf NU-A [(19440, 19920, 'GlossL S2'), (49280, 49360, 'GlossL S2'), (50440, 50600, 'GlossL S2'), (70320, 70760, 'GlossL S2')]\n",
      "S058_CNGT1330.eaf NU-A [(93560, 93880, 'GlossR S2')]\n",
      "S071_CNGT1712.eaf NU-A [(5400, 5840, 'GlossR S1'), (6360, 6480, 'GlossR S1')]\n",
      "S072_CNGT1730.eaf NU-A [(69960, 70320, 'GlossR S2')]\n",
      "S073_CNGT1771.eaf NU-A [(71880, 72080, 'GlossL S1')]\n",
      "S079_CNGT1986.eaf NU-A [(125960, 126080, 'GlossR S1')]\n",
      "S080_CNGT1986.eaf NU-A [(19320, 19480, 'GlossR S2'), (21205, 21305, 'GlossR S2'), (35314, 35400, 'GlossR S2')]\n",
      "S082_CNGT2035.eaf NU-A [(144920, 145160, 'GlossR S2')]\n",
      "S085_CNGT2152.eaf NU-A [(21120, 21280, 'GlossR S1')]\n"
     ]
    }
   ],
   "source": [
    "# For a target gloss, we find all videos in the test set that contain it\n",
    "# So we can use one of those videos for the sliding window during sign spotting\n",
    "target_gloss = 'NU-A'\n",
    "for video_id in anns_with_tiers:\n",
    "    gloss_dict = anns_with_tiers[video_id]\n",
    "    for gloss in gloss_dict:\n",
    "        if gloss == target_gloss and video_id in test_ids:\n",
    "            print(video_id, gloss, gloss_dict[gloss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e9988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
